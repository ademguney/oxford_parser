# Oxford Vocabulary Parser

This project aims to extract and structure English vocabulary data from two official resources:

- **The Oxford 3000** â€” A list of the 3000 most important English words for learners from A1 to B2 levels.
- **American Oxford 5000** â€” A comprehensive list covering more advanced and frequently used words (B2 and above).

The ultimate goal is to convert this raw PDF content into structured JSON format and store the parsed data into a relational database (PostgreSQL). This forms the foundational dataset for an LLM-powered Flashcard application for English learners.

---

## ğŸš€ Project Goals

- ğŸ“¥ Extract vocabulary, word type (part of speech), and CEFR level (A1â€“C1) from PDF files
- ğŸ”„ Convert to clean and structured JSON
- ğŸ§  (Optional Next Step) Use LLMs like GPT-4 to generate:
  - Translations
  - Most common daily-use example sentences (up to 3 per word)
- ğŸ—ƒï¸ Store the final data into PostgreSQL for use in flashcard-based learning systems

---

## ğŸ“š Input Files

- `The_Oxford_3000.pdf`
- `American_Oxford_5000.pdf`

These files must be placed inside the `/data` directory.

---

## ğŸ§± Project Structure

```bash
oxford_parser/
â”‚
â”œâ”€â”€ main.py                  # Entry point
â”œâ”€â”€ parser/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ pdf_extractor.py     # PDF parsing logic
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ The_Oxford_3000.pdf
â”‚   â””â”€â”€ American_Oxford_5000.pdf
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
